#![allow(dead_code, unused_imports)]
#![allow(rustdoc::broken_intra_doc_links, rustdoc::invalid_html_tags)]
//! # Cultivo EpistÃªmico â€” Semantic Chat
//!
//! **Ponto de entrada principal** da aplicaÃ§Ã£o Cultivo EpistÃªmico.
//!
//! Este arquivo inicializa todos os componentes do sistema e inicia o servidor web.
//! A arquitetura segue um padrÃ£o de inicializaÃ§Ã£o em duas fases:
//!
//! 1. **Fase imediata**: O servidor web (axum) Ã© iniciado e comeÃ§a a aceitar conexÃµes
//!    em `http://localhost:3000` instantaneamente
//! 2. **Fase background**: O modelo BERTimbau (~400MB) Ã© carregado em uma thread
//!    separada via `tokio::task::spawn_blocking`, sem bloquear o servidor
//!
//! ## Fluxo de InicializaÃ§Ã£o
//!
//! ```text
//! main()
//!   â”œâ”€â”€ Configura tracing/logging
//!   â”œâ”€â”€ Carrega KB do disco (ou cria vazia)
//!   â”œâ”€â”€ Cria broadcast channel para SSE
//!   â”œâ”€â”€ Monta AppState e Router
//!   â”œâ”€â”€ Inicia servidor TCP (porta 3000)
//!   â””â”€â”€ Spawn background:
//!       â”œâ”€â”€ Carrega BERTimbau via HuggingFace Hub
//!       â”œâ”€â”€ Cria NluPipeline
//!       â”œâ”€â”€ Cria Orchestrator
//!       â””â”€â”€ Publica em OnceLock (ModelReady)
//! ```
//!
//! ## Exemplo de Uso
//!
//! ```bash
//! # Executar com logs padrÃ£o (info)
//! cargo run
//!
//! # Executar com logs detalhados
//! RUST_LOG=debug cargo run
//!
//! # O servidor estarÃ¡ disponÃ­vel em http://localhost:3000
//! ```
//!
//! ## Caso de Uso
//!
//! O sistema permite que um usuÃ¡rio converse em linguagem natural (portuguÃªs),
//! e automaticamente:
//! - Extrai conceitos do texto
//! - Encontra relaÃ§Ãµes semÃ¢nticas entre conceitos
//! - Realiza inferÃªncias lÃ³gicas (NARS)
//! - Faz perguntas reflexivas para aprofundar o conhecimento
//! - Visualiza o grafo de conhecimento em 3D

// DeclaraÃ§Ã£o dos mÃ³dulos da aplicaÃ§Ã£o.
// Cada mÃ³dulo corresponde a uma camada da arquitetura:

/// MÃ³dulo `core` â€” tipos fundamentais: Concept, Link, TruthValue, KnowledgeBase.
mod core;

/// MÃ³dulo `inference` â€” motor de inferÃªncia NARS (deduÃ§Ã£o, induÃ§Ã£o).
mod inference;

/// MÃ³dulo `metrics` â€” coleta de mÃ©tricas de sistema (CPU, RAM, GPU).
mod metrics;

/// MÃ³dulo `nlu` â€” pipeline de compreensÃ£o de linguagem natural (BERTimbau).
mod nlu;

/// MÃ³dulo `orchestrator` â€” orquestra o ciclo de cultivo epistÃªmico.
mod orchestrator;

/// MÃ³dulo `pdf` â€” ingestÃ£o e processamento de documentos PDF.
mod pdf;

/// MÃ³dulo `persistence` â€” serializaÃ§Ã£o/desserializaÃ§Ã£o da KB em JSON.
mod persistence;

/// MÃ³dulo `web` â€” servidor web axum, handlers HTTP, templates e SSE.
mod web;

use std::sync::{Arc, OnceLock};

use anyhow::Result;
use parking_lot::{Mutex, RwLock};
use tokio::sync::broadcast;
use tracing_subscriber::EnvFilter;

use crate::core::KnowledgeBase;
use crate::nlu::embedder::Embedder;
use crate::nlu::NluPipeline;
use crate::orchestrator::Orchestrator;
use crate::web::events::IngestionEvent;
use crate::web::state::{AppState, ModelReady};

/// FunÃ§Ã£o principal assÃ­ncrona do Cultivo EpistÃªmico.
///
/// Inicializa o sistema em duas fases:
/// - **Fase 1 (sÃ­ncrona)**: Carrega KB, cria estado compartilhado, inicia servidor
/// - **Fase 2 (background)**: Carrega modelo ML, cria pipeline NLU e orquestrador
///
/// O servidor fica acessÃ­vel imediatamente enquanto o modelo carrega em background.
/// Quando o modelo termina de carregar, o `OnceLock` Ã© preenchido e o sistema
/// passa a responder mensagens de chat.
///
/// # Erros
///
/// Retorna erro se:
/// - NÃ£o conseguir fazer bind na porta 3000
/// - O servidor axum falhar durante execuÃ§Ã£o
#[tokio::main]
async fn main() -> Result<()> {
    // Configura o sistema de logging/tracing.
    // Aceita a variÃ¡vel de ambiente RUST_LOG para configurar o nÃ­vel.
    // Exemplo: RUST_LOG=debug cargo run
    tracing_subscriber::fmt()
        .with_env_filter(
            EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info")),
        )
        .init();

    tracing::info!("ðŸŒ± Cultivo EpistÃªmico â€” Starting...");

    // Tenta carregar a base de conhecimento do disco (data/kb.json).
    // Se o arquivo nÃ£o existir ou estiver corrompido, inicia com KB vazia.
    // A KB Ã© envolta em Arc<RwLock<>> para acesso concorrente seguro.
    let kb = match persistence::load_kb() {
        Ok(loaded_kb) => {
            tracing::info!(
                concepts = loaded_kb.concept_count(),
                links = loaded_kb.link_count(),
                "KB carregada do disco"
            );
            Arc::new(RwLock::new(loaded_kb))
        }
        Err(e) => {
            tracing::warn!(error = %e, "Falha ao carregar KB do disco, iniciando vazia");
            Arc::new(RwLock::new(KnowledgeBase::new()))
        }
    };

    // OnceLock para o modelo ML â€” serÃ¡ preenchido quando o modelo terminar de carregar.
    // Enquanto estiver vazio, o servidor responde "modelo carregando...".
    let model = Arc::new(OnceLock::new());

    // Canal broadcast para eventos SSE (Server-Sent Events).
    // Usado para streaming em tempo real durante a ingestÃ£o de PDFs.
    // Capacidade de 256 eventos â€” mensagens antigas sÃ£o descartadas se o consumidor for lento.
    let (events_tx, _) = broadcast::channel::<IngestionEvent>(256);
    let events_tx = Arc::new(events_tx);

    // Estado compartilhado da aplicaÃ§Ã£o â€” passado para todos os handlers via axum State.
    let state = AppState {
        model: model.clone(),
        kb: kb.clone(),
        events_tx,
    };

    // Cria o router com todas as rotas da aplicaÃ§Ã£o.
    let app = web::create_router(state);

    // Inicia o servidor TCP â€” o servidor fica acessÃ­vel IMEDIATAMENTE,
    // mesmo antes do modelo ML terminar de carregar.
    let addr = "0.0.0.0:3000";
    let listener = tokio::net::TcpListener::bind(addr).await?;
    tracing::info!("ðŸš€ Server running at http://localhost:3000");

    // Carrega o modelo BERTimbau em uma thread de background.
    // Usa spawn_blocking porque o carregamento do modelo Ã© uma operaÃ§Ã£o
    // CPU-intensiva que bloquearia o runtime tokio se fosse feita inline.
    tokio::task::spawn_blocking(move || {
        tracing::info!("Loading BERTimbau model (first run downloads ~400MB)...");

        // Carrega o modelo de embeddings BERTimbau.
        // Na primeira execuÃ§Ã£o, faz download dos pesos do HuggingFace Hub.
        let embedder = match Embedder::load() {
            Ok(e) => e,
            Err(e) => {
                tracing::error!("Failed to load embedder: {}", e);
                return;
            }
        };
        tracing::info!("Model loaded!");

        // Cria o pipeline NLU completo (embedder + classificador de intent + extrator).
        let nlu = match NluPipeline::new(embedder) {
            Ok(n) => Arc::new(n),
            Err(e) => {
                tracing::error!("Failed to create NLU pipeline: {}", e);
                return;
            }
        };
        tracing::info!("NLU pipeline initialized.");

        // Cria o orquestrador do ciclo epistÃªmico.
        let orchestrator = Mutex::new(Orchestrator::new(nlu.clone(), kb.clone()));

        // Publica o modelo no OnceLock â€” a partir deste ponto,
        // todos os handlers que verificam state.model.get() saberÃ£o que estÃ¡ pronto.
        let _ = model.set(ModelReady { orchestrator, nlu });
        tracing::info!("âœ… System ready!");
    });

    // Inicia o servidor axum â€” bloqueia atÃ© que o processo seja encerrado.
    axum::serve(listener, app).await?;

    Ok(())
}
